# @package _global_
train:
  interval: epoch
scheduler:
  # _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _name_: cosine
  T_max: ${trainer.max_epochs} #100  # Max number of epochs steps for LR scheduler
  eta_min: 1.0e-4 #1e-6  # Min learning rate for cosine scheduler
